{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091eb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "api_key = config[\"openai\"][\"api_key\"]\n",
    "model = config[\"openai\"][\"default_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649b28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We've got this part nailed down, I think.\n",
    "from tools import tool_method, tool_manager, create_react_tool_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cd5708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Successfully updated key 'example_key' from 'not found' to 'example_value'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool_manager\n",
    "class DictionaryToolManager:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    \n",
    "    @tool_method\n",
    "    def get_value(self, key: str) -> str:\n",
    "        \"\"\"Get a value from the dictionary by key.\"\"\"\n",
    "        try:\n",
    "            if key in self.data:\n",
    "                value = self.data[key]\n",
    "                return f\"Value for key '{key}': {value}\"\n",
    "            else:\n",
    "                return f\"Key '{key}' not found in dictionary. Available keys: {list(self.data.keys())}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error getting value: {str(e)}\"\n",
    "        \n",
    "    @tool_method\n",
    "    def update_value(self, key: str, value: str) -> str:\n",
    "        \"\"\"Update or add a key-value pair in the dictionary.\"\"\"\n",
    "        try:\n",
    "            old_value = self.data.get(key, \"not found\")\n",
    "            self.data[key] = value\n",
    "            return f\"Successfully updated key '{key}' from '{old_value}' to '{value}'\"\n",
    "        except Exception as e:\n",
    "            return f\"Error updating value: {str(e)}\"\n",
    "        \n",
    "    @tool_method\n",
    "    def list_keys(self) -> str:\n",
    "        \"\"\"List all keys in the dictionary.\"\"\"\n",
    "        try:\n",
    "            keys = list(self.data.keys())\n",
    "            if keys:\n",
    "                return f\"Dictionary keys ({len(keys)}): {keys}\"\n",
    "            else:\n",
    "                return \"Dictionary is empty (no keys found)\"\n",
    "        except Exception as e:\n",
    "            return f\"Error listing keys: {str(e)}\"\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "my_tool_manager = DictionaryToolManager()\n",
    "my_tool_manager.update_value(\"example_key\", \"example_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9dfb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Can you use the tools provided to get the value for 'example_key'?\",\n",
       " 'chat_history': [],\n",
       " 'output': \"The value for 'example_key' is: example_value.\",\n",
       " 'intermediate_steps': [(ToolAgentAction(tool='get_value', tool_input={'key': 'example_key'}, log=\"\\nInvoking: `get_value` with `{'key': 'example_key'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_KyZkUg8pLnpYzXyHQVqilOv6', 'function': {'arguments': '{\"key\":\"example_key\"}', 'name': 'get_value'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'service_tier': 'default'}, id='run--17d72b46-8abd-47ca-9772-f763f932e149', tool_calls=[{'name': 'get_value', 'args': {'key': 'example_key'}, 'id': 'call_KyZkUg8pLnpYzXyHQVqilOv6', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'get_value', 'args': '{\"key\":\"example_key\"}', 'id': 'call_KyZkUg8pLnpYzXyHQVqilOv6', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_KyZkUg8pLnpYzXyHQVqilOv6'),\n",
       "   \"Value for key 'example_key': example_value\")]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_react_tool_agent(\n",
    "    model = \"gpt-4.1\",\n",
    "    api_key = api_key,\n",
    "    tools = my_tool_manager.get_tools()\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "test_message = \"Can you use the tools provided to get the value for 'example_key'?\"\n",
    "result = agent.invoke({\"input\": test_message, \"chat_history\": chat_history})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad73e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## So what actually needs to happen here?  There exist potentially at least three different message formats:\n",
    "# 1. OpenAI's message format, which is a list of dictionaries with \"role\" and \"content\" keys.\n",
    "# 2. LangChain's message format, which uses classes like `HumanMessage`, `AIMessage`, and `SystemMessage`.\n",
    "# 3. Chainlit's message format, which is a list of `Message` objects that can include tool calls and observations.\n",
    "\n",
    "# What is acually required?\n",
    "# - We don't actually ever need to see the OpenAI message format directly, but it does have the nice property of being primitives.\n",
    "# - LangChain is what actually processes the messages.\n",
    "# - ChainLit only ever sees the messages that get shown to the user, which does not include the tool calls or observations.\n",
    "# - It looks like the conversions mostly just involve copying over .content\n",
    "# - For LangChain, we're mostly just using HumanMessage nad AIMessage (plus the tool stuff, potentially)\n",
    "# - For ChainList, we have just one message type, and we can infer the type based on whether we the app is sending or receiving it.\n",
    "from langchain_core.messages.tool import ToolCall, ToolMessage\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from chainlit import Message\n",
    "from typing import Union\n",
    "\n",
    "class ChatHistoryManager:\n",
    "    @staticmethod\n",
    "    def chainlit_to_langchain(messages: Union[Message, list[Message]]) -> list:\n",
    "        if isinstance(messages, Message):\n",
    "            messages = [messages]\n",
    "        # You only ever need to convert user messages\n",
    "        return [HumanMessage(content=msg.content) for msg in messages if msg.type == \"user\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def langchain_to_chainlit(messages: list) -> list:\n",
    "        # It seems like this would mostly be about converting AssistantMessage to ChainLit Message\n",
    "        # I actually don't remember; in ChainList, do we by default *see* previous user messages?\n",
    "        if isinstance(messages, HumanMessage):\n",
    "            messages = [messages]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def add_message(self, message: str):\n",
    "        self.history.append(message)\n",
    "\n",
    "    # call this on the intermediate steps\n",
    "    def parse_tool_messages(self, steps) -> list:\n",
    "        # rumor has it these don't work very well\n",
    "        tool_messages = []\n",
    "        for step in steps:\n",
    "            tool_call, tool_observation = result[\"intermediate_steps\"][0]\n",
    "            tool_call_message = ToolCall(\n",
    "                name = tool_call.tool,\n",
    "                args = tool_call.tool_input,\n",
    "                id = tool_call.tool_call_id,\n",
    "            )\n",
    "            tool_message = ToolMessage(\n",
    "                content = tool_observation,\n",
    "                tool_call_id = tool_call.tool_call_id,\n",
    "            )\n",
    "            tool_messages.append(tool_call_message)\n",
    "            tool_messages.append(tool_message)\n",
    "        return tool_messages\n",
    "    \n",
    "    def get_history(self) -> list:\n",
    "        return [msg for msg in self.history]\n",
    "\n",
    "    def filter_history(self) -> list:\n",
    "        # I'm not actually sure how we should do this...\n",
    "        # For now, just return all messages\n",
    "        return [msg for msg in self.history]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf65abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.tool import ToolCall, ToolMessage\n",
    "tool_call, tool_observation = result[\"intermediate_steps\"][0]\n",
    "tool_call_message = ToolCall(\n",
    "    name = tool_call.tool,\n",
    "    args = tool_call.tool_input,\n",
    "    id = tool_call.tool_call_id,\n",
    ")\n",
    "tool_message = ToolMessage(\n",
    "    content = tool_observation,\n",
    "    tool_call_id = tool_call.tool_call_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa8cbfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ToolMessage in module langchain_core.messages.tool:\n",
      "\n",
      "class ToolMessage(langchain_core.messages.base.BaseMessage, ToolOutputMixin)\n",
      " |  ToolMessage(content: Union[str, list[Union[str, dict]]], *, additional_kwargs: dict = <factory>, response_metadata: dict = <factory>, type: Literal['tool'] = 'tool', name: Optional[str] = None, id: Annotated[Optional[str], _PydanticGeneralMetadata(coerce_numbers_to_str=True)] = None, tool_call_id: str, artifact: Any = None, status: Literal['success', 'error'] = 'success', **kwargs: Any) -> None\n",
      " |  \n",
      " |  Message for passing the result of executing a tool back to a model.\n",
      " |  \n",
      " |  ToolMessages contain the result of a tool invocation. Typically, the result\n",
      " |  is encoded inside the `content` field.\n",
      " |  \n",
      " |  Example: A ToolMessage representing a result of 42 from a tool call with id\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain_core.messages import ToolMessage\n",
      " |  \n",
      " |          ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')\n",
      " |  \n",
      " |  \n",
      " |  Example: A ToolMessage where only part of the tool output is sent to the model\n",
      " |      and the full output is passed in to artifact.\n",
      " |  \n",
      " |      .. versionadded:: 0.2.17\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain_core.messages import ToolMessage\n",
      " |  \n",
      " |          tool_output = {\n",
      " |              \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\n",
      " |              \"stderr\": None,\n",
      " |              \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\n",
      " |          }\n",
      " |  \n",
      " |          ToolMessage(\n",
      " |              content=tool_output[\"stdout\"],\n",
      " |              artifact=tool_output,\n",
      " |              tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',\n",
      " |          )\n",
      " |  \n",
      " |  The tool_call_id field is used to associate the tool call request with the\n",
      " |  tool call response. This is useful in situations where a chat model is able\n",
      " |  to request multiple tool calls in parallel.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ToolMessage\n",
      " |      langchain_core.messages.base.BaseMessage\n",
      " |      langchain_core.load.serializable.Serializable\n",
      " |      pydantic.main.BaseModel\n",
      " |      abc.ABC\n",
      " |      ToolOutputMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, content: Union[str, list[Union[str, dict]]], **kwargs: Any) -> None\n",
      " |      Create a ToolMessage.\n",
      " |      \n",
      " |      Args:\n",
      " |          content: The string contents of the message.\n",
      " |          **kwargs: Additional fields.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  coerce_args(values: dict) -> dict from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Coerce the model arguments to the correct types.\n",
      " |      \n",
      " |      Args:\n",
      " |          values: The model arguments.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'additional_kwargs': <class 'dict'>, 'artifact': ty...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __private_attributes__ = {}\n",
      " |  \n",
      " |  __pydantic_complete__ = True\n",
      " |  \n",
      " |  __pydantic_computed_fields__ = {}\n",
      " |  \n",
      " |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.messages.too...\n",
      " |  \n",
      " |  __pydantic_custom_init__ = True\n",
      " |  \n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |  \n",
      " |  __pydantic_fields__ = {'additional_kwargs': FieldInfo(annotation=dict,...\n",
      " |  \n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |  \n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |  \n",
      " |  __pydantic_post_init__ = None\n",
      " |  \n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |  \n",
      " |  __pydantic_setattr_handlers__ = {}\n",
      " |  \n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"ToolMessage\", validato...\n",
      " |  \n",
      " |  __signature__ = <Signature (content: Union[str, list[Union[str, ...s',...\n",
      " |  \n",
      " |  model_config = {'extra': 'allow'}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.messages.base.BaseMessage:\n",
      " |  \n",
      " |  __add__(self, other: 'Any') -> 'ChatPromptTemplate'\n",
      " |      Concatenate this message with another message.\n",
      " |  \n",
      " |  pretty_print(self) -> 'None'\n",
      " |      Print a pretty representation of the message.\n",
      " |  \n",
      " |  pretty_repr(self, html: 'bool' = False) -> 'str'\n",
      " |      Get a pretty representation of the message.\n",
      " |      \n",
      " |      Args:\n",
      " |          html: Whether to format the message as HTML. If True, the message will be\n",
      " |              formatted with HTML tags. Default is False.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pretty representation of the message.\n",
      " |  \n",
      " |  text(self) -> 'str'\n",
      " |      Get the text content of the message.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The text content of the message.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.messages.base.BaseMessage:\n",
      " |  \n",
      " |  get_lc_namespace() -> 'list[str]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Get the namespace of the langchain object.\n",
      " |      \n",
      " |      Default is [\"langchain\", \"schema\", \"messages\"].\n",
      " |  \n",
      " |  is_lc_serializable() -> 'bool' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      BaseMessage is serializable.\n",
      " |      \n",
      " |      Returns:\n",
      " |          True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  __repr_args__(self) -> Any\n",
      " |  \n",
      " |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]\n",
      " |      Serialize the object to JSON.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A json serializable object or a SerializedNotImplemented object.\n",
      " |  \n",
      " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
      " |      Serialize a \"not implemented\" object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_id() -> list[str] from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      A unique identifier for this class for serialization purposes.\n",
      " |      \n",
      " |      The unique identifier is a list of strings that describes the path\n",
      " |      to the object.\n",
      " |      For example, for the class `langchain.llms.openai.OpenAI`, the id is\n",
      " |      [\"langchain\", \"llms\", \"openai\", \"OpenAI\"].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_attributes\n",
      " |      List of attribute names that should be included in the serialized kwargs.\n",
      " |      \n",
      " |      These attributes must be accepted by the constructor.\n",
      " |      Default is an empty dictionary.\n",
      " |  \n",
      " |  lc_secrets\n",
      " |      A map of constructor argument names to secret ids.\n",
      " |      \n",
      " |      For example,\n",
      " |          {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |  \n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |  \n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |  \n",
      " |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |  \n",
      " |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      " |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      " |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_name__(self) -> 'str'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_recursion__(self, object: 'Any') -> 'str'\n",
      " |      Returns the string representation of a recursive object.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'str') -> 'str'\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! warning \"Deprecated\"\n",
      " |          This method is now deprecated; use `model_copy` instead.\n",
      " |      \n",
      " |      If you need `include` or `exclude`, use:\n",
      " |      \n",
      " |      ```python {test=\"skip\" lint=\"skip\"}\n",
      " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      " |      data = {**data, **(update or {})}\n",
      " |      copied = self.model_validate(data)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A copy of the model with included, excluded and updated fields as specified.\n",
      " |  \n",
      " |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      " |  \n",
      " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      " |  \n",
      " |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_copy`](../concepts/serialization.md#model_copy)\n",
      " |      \n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! note\n",
      " |          The underlying instance's [`__dict__`][object.__dict__] attribute is copied. This\n",
      " |          might have unexpected side effects if you store anything in it, on top of the model\n",
      " |          fields (e.g. the value of [cached properties][functools.cached_property]).\n",
      " |      \n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |  \n",
      " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump`](../concepts/serialization.md#modelmodel_dump)\n",
      " |      \n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |  \n",
      " |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'str'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump_json`](../concepts/serialization.md#modelmodel_dump_json)\n",
      " |      \n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |  \n",
      " |  model_post_init(self, context: 'Any', /) -> 'None'\n",
      " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |      \n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |  \n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called.\n",
      " |      \n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |      \n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by pydantic.\n",
      " |  \n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |      \n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      \n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |      \n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |  \n",
      " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Generates a JSON schema for a model class.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |  \n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |      \n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |      \n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |  \n",
      " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |      \n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |      \n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |  \n",
      " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate a pydantic model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |  \n",
      " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [JSON Parsing](../concepts/json.md#json-parsing)\n",
      " |      \n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |  \n",
      " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |  \n",
      " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |  \n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __pydantic_extra__\n",
      " |  \n",
      " |  __pydantic_fields_set__\n",
      " |  \n",
      " |  __pydantic_private__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __pydantic_root_model__ = False\n",
      " |  \n",
      " |  model_computed_fields = {}\n",
      " |  \n",
      " |  model_fields = {'additional_kwargs': FieldInfo(annotation=dict, requir...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ToolMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1fd26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'get_value',\n",
       "  'args': {'key': 'example_key'},\n",
       "  'id': 'call_KyZkUg8pLnpYzXyHQVqilOv6'},\n",
       " ToolMessage(content=\"Value for key 'example_key': example_value\", tool_call_id='call_KyZkUg8pLnpYzXyHQVqilOv6'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_message, tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728252f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ef772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.tool import ToolCall, ToolMessage\n",
    "\n",
    "# Extract the intermediate step data\n",
    "action, observation = result.intermediate_steps[0]  # First (and only) step\n",
    "\n",
    "# Create ToolCall instance\n",
    "tool_call = ToolCall(\n",
    "    name=action.tool,                    # \"get_value\"\n",
    "    args=action.tool_input,              # {\"key\": \"example_key\"}\n",
    "    id=action.tool_call_id               # \"call_KyZkUg8pLnpYzXyHQVqilOv6\"\n",
    ")\n",
    "\n",
    "# Create ToolMessage instance\n",
    "tool_message = ToolMessage(\n",
    "    content=observation,                 # \"Value for key 'example_key': example_value\"\n",
    "    tool_call_id=action.tool_call_id     # \"call_KyZkUg8pLnpYzXyHQVqilOv6\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
